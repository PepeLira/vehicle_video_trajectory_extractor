{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f81e824",
   "metadata": {},
   "source": [
    "# Análisis Seguimiento de Vehículos en Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb7d163",
   "metadata": {},
   "source": [
    "## Introducción y Descripción General\n",
    "Este Jupyter Notebook proporciona un análisis detallado del código suministrado para el seguimiento de vehículos en un video. Utiliza el modelo YOLOv8 para la detección de objetos y SORT para el seguimiento de objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f24bade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from sort import Sort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134a964a",
   "metadata": {},
   "source": [
    "## Importación de Librerías Necesarias:\n",
    "- `numpy`: Para operaciones matemáticas y manejo de arrays.\n",
    "- `cv2` (OpenCV): Para el procesamiento de imágenes y video.\n",
    "- `ultralytics.YOLOv8`: Un modelo pre-entrenado de detección de objetos.\n",
    "- `sort.Sort`: Un algoritmo de seguimiento de objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83056f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resize_frame(frame, max_width=1920, max_height=1080):\n",
    "    h, w = frame.shape[:2]\n",
    "    scale = min(max_width / w, max_height / h)\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    return cv2.resize(frame, (new_w, new_h))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b9a477",
   "metadata": {},
   "source": [
    "## Función `resize_frame`\n",
    "Esta función redimensiona los frames del video manteniendo la relación de aspecto. Se utiliza para asegurar que el tamaño de los frames sea manejable para el procesamiento y visualización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219c7d27",
   "metadata": {},
   "source": [
    "## Inicialización de Componentes Principales\n",
    "El código inicializa componentes clave para la captura de video, detección de objetos y seguimiento:\n",
    "1. **Captura de Video**: Se carga el video usando `cv2.VideoCapture`.\n",
    "2. **Modelo YOLO**: Se inicializa el modelo YOLO para la detección de objetos en el video.\n",
    "3. **Tracker SORT**: Se inicializa el tracker SORT para el seguimiento de objetos detectados por YOLO.\n",
    "\n",
    "Es necesario entregar como base un video de prueba para `VideoCapture`. Además de un modelo pre-entrenado de YOLOv8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c0f6340",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"D:/Titulo/Github/vehicle_video_trajectory_extractor/videos/video_sim_30s_movement_estabilizado_filtrado.mp4\")\n",
    "model = YOLO(\"D:/Titulo/Github/vehicle_video_trajectory_extractor/models/cutom_dota.pt\")\n",
    "tracker = Sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a676a16f",
   "metadata": {},
   "source": [
    "## Ciclo Principal de Procesamiento de Video\n",
    "El ciclo principal gestiona la lectura de cada frame, la detección de objetos, el seguimiento y la visualización:\n",
    "- **Lectura de Frame**: Se lee cada frame del video.\n",
    "- **Detección con YOLO**: Se detectan objetos en cada frame usando el modelo YOLO.\n",
    "- **Filtrado y Seguimiento**: Se filtran las detecciones y se realiza el seguimiento de los vehículos.\n",
    "- **Dibujar Resultados en Frame**: Se dibujan los identificadores y cuadros delimitadores en cada frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60da8a4",
   "metadata": {},
   "source": [
    "## Visualización y Salida\n",
    "El código muestra el video procesado y permite al usuario finalizar la visualización presionando una tecla específica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8c7c94",
   "metadata": {},
   "source": [
    "## Limpieza de Recursos\n",
    "Es crucial liberar recursos como la captura de video y las ventanas de OpenCV para evitar fugas de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f93f8ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 576x1024 2 large vehicles, 26 small vehicles, 10.0ms\n",
      "Speed: 6.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 1024)\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
      "conf: tensor([0.7510, 0.6731, 0.6155, 0.6014, 0.5832, 0.5771, 0.5656, 0.5601, 0.5102, 0.4956, 0.4488, 0.4300, 0.4117, 0.4001, 0.3864, 0.3833, 0.3701, 0.3690, 0.3652, 0.3649, 0.3581, 0.3320, 0.3302, 0.3295, 0.3116, 0.2931, 0.2896, 0.2760], device='cuda:0')\n",
      "data: tensor([[1.3901e+03, 6.4305e+02, 1.4271e+03, 6.7885e+02, 7.5103e-01, 1.0000e+00],\n",
      "        [1.1181e+03, 1.4863e+03, 1.1453e+03, 1.5232e+03, 6.7314e-01, 1.0000e+00],\n",
      "        [1.1831e+03, 1.1737e+03, 1.2035e+03, 1.2131e+03, 6.1553e-01, 1.0000e+00],\n",
      "        [1.0654e+03, 2.8567e+02, 1.0966e+03, 3.1933e+02, 6.0142e-01, 1.0000e+00],\n",
      "        [1.0916e+03, 1.5383e+03, 1.1180e+03, 1.5737e+03, 5.8324e-01, 1.0000e+00],\n",
      "        [1.8290e+03, 9.4086e+00, 1.8458e+03, 4.7690e+01, 5.7713e-01, 1.0000e+00],\n",
      "        [1.2979e+03, 7.4121e+02, 1.3339e+03, 7.8558e+02, 5.6561e-01, 1.0000e+00],\n",
      "        [1.2645e+03, 8.1981e+02, 1.2919e+03, 8.5790e+02, 5.6007e-01, 1.0000e+00],\n",
      "        [1.2433e+03, 8.9297e+02, 1.2661e+03, 9.3068e+02, 5.1018e-01, 1.0000e+00],\n",
      "        [2.3424e+03, 3.8511e+02, 2.3594e+03, 4.0830e+02, 4.9557e-01, 1.0000e+00],\n",
      "        [3.8990e+02, 7.9310e+01, 4.0619e+02, 1.1230e+02, 4.4876e-01, 1.0000e+00],\n",
      "        [1.1665e+03, 1.6075e+02, 1.1999e+03, 1.9866e+02, 4.3001e-01, 1.0000e+00],\n",
      "        [2.3672e+03, 3.8346e+02, 2.3887e+03, 4.0772e+02, 4.1171e-01, 1.0000e+00],\n",
      "        [1.9669e+03, 6.7224e+02, 2.0528e+03, 7.3342e+02, 4.0012e-01, 0.0000e+00],\n",
      "        [1.2291e+03, 1.2732e+03, 1.2462e+03, 1.3115e+03, 3.8636e-01, 1.0000e+00],\n",
      "        [1.4758e+03, 6.0151e+02, 1.5125e+03, 6.3009e+02, 3.8330e-01, 1.0000e+00],\n",
      "        [3.9703e+02, 3.0885e+02, 4.1205e+02, 3.4340e+02, 3.7013e-01, 1.0000e+00],\n",
      "        [1.8346e+03, 2.0919e+02, 1.8504e+03, 2.4357e+02, 3.6897e-01, 1.0000e+00],\n",
      "        [2.1851e+03, 8.2932e+02, 2.2268e+03, 8.8544e+02, 3.6517e-01, 0.0000e+00],\n",
      "        [8.1411e+02, 5.0785e+02, 8.4581e+02, 5.3773e+02, 3.6493e-01, 1.0000e+00],\n",
      "        [1.2661e+03, 1.0715e+03, 1.2888e+03, 1.1085e+03, 3.5810e-01, 1.0000e+00],\n",
      "        [3.8962e+02, 6.5137e-01, 4.0409e+02, 2.0538e+01, 3.3198e-01, 1.0000e+00],\n",
      "        [2.5239e+03, 7.4543e+02, 2.5402e+03, 7.7838e+02, 3.3020e-01, 1.0000e+00],\n",
      "        [7.5287e+02, 5.4400e+02, 8.0301e+02, 5.8701e+02, 3.2950e-01, 1.0000e+00],\n",
      "        [2.4805e+03, 2.4170e+02, 2.4960e+03, 2.7244e+02, 3.1164e-01, 1.0000e+00],\n",
      "        [6.8673e+02, 1.2745e+03, 7.2250e+02, 1.2906e+03, 2.9309e-01, 1.0000e+00],\n",
      "        [7.4672e+02, 5.5277e+02, 7.9253e+02, 5.9310e+02, 2.8956e-01, 1.0000e+00],\n",
      "        [1.8383e+03, 3.8987e+02, 1.8526e+03, 4.2682e+02, 2.7599e-01, 1.0000e+00]], device='cuda:0')\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1620, 2880)\n",
      "shape: torch.Size([28, 6])\n",
      "xywh: tensor([[1408.5757,  660.9489,   37.0171,   35.8040],\n",
      "        [1131.6885, 1504.7144,   27.1697,   36.8722],\n",
      "        [1193.3291, 1193.4082,   20.4003,   39.4281],\n",
      "        [1081.0393,  302.4976,   31.1906,   33.6588],\n",
      "        [1104.7847, 1556.0054,   26.3719,   35.3911],\n",
      "        [1837.4309,   28.5492,   16.8365,   38.2812],\n",
      "        [1315.9082,  763.3960,   35.9688,   44.3691],\n",
      "        [1278.1742,  838.8556,   27.3860,   38.0909],\n",
      "        [1254.6881,  911.8257,   22.7888,   37.7037],\n",
      "        [2350.8843,  396.7076,   16.9963,   23.1916],\n",
      "        [ 398.0468,   95.8056,   16.2840,   32.9906],\n",
      "        [1183.2192,  179.7078,   33.3533,   37.9070],\n",
      "        [2377.9419,  395.5905,   21.4700,   24.2556],\n",
      "        [2009.8785,  702.8293,   85.9128,   61.1755],\n",
      "        [1237.6348, 1292.3530,   17.1177,   38.3877],\n",
      "        [1494.1838,  615.7996,   36.7273,   28.5724],\n",
      "        [ 404.5417,  326.1271,   15.0150,   34.5532],\n",
      "        [1842.5065,  226.3757,   15.7695,   34.3814],\n",
      "        [2205.9541,  857.3751,   41.6792,   56.1202],\n",
      "        [ 829.9623,  522.7892,   31.6952,   29.8806],\n",
      "        [1277.4683, 1090.0161,   22.6960,   36.9999],\n",
      "        [ 396.8558,   10.5949,   14.4777,   19.8871],\n",
      "        [2532.0171,  761.9061,   16.3010,   32.9471],\n",
      "        [ 777.9410,  565.5035,   50.1409,   43.0036],\n",
      "        [2488.2371,  257.0679,   15.5449,   30.7420],\n",
      "        [ 704.6124, 1282.5410,   35.7673,   16.1389],\n",
      "        [ 769.6211,  572.9319,   45.8120,   40.3320],\n",
      "        [1845.4521,  408.3442,   14.3035,   36.9432]], device='cuda:0')\n",
      "xywhn: tensor([[0.4891, 0.4080, 0.0129, 0.0221],\n",
      "        [0.3929, 0.9288, 0.0094, 0.0228],\n",
      "        [0.4144, 0.7367, 0.0071, 0.0243],\n",
      "        [0.3754, 0.1867, 0.0108, 0.0208],\n",
      "        [0.3836, 0.9605, 0.0092, 0.0218],\n",
      "        [0.6380, 0.0176, 0.0058, 0.0236],\n",
      "        [0.4569, 0.4712, 0.0125, 0.0274],\n",
      "        [0.4438, 0.5178, 0.0095, 0.0235],\n",
      "        [0.4357, 0.5629, 0.0079, 0.0233],\n",
      "        [0.8163, 0.2449, 0.0059, 0.0143],\n",
      "        [0.1382, 0.0591, 0.0057, 0.0204],\n",
      "        [0.4108, 0.1109, 0.0116, 0.0234],\n",
      "        [0.8257, 0.2442, 0.0075, 0.0150],\n",
      "        [0.6979, 0.4338, 0.0298, 0.0378],\n",
      "        [0.4297, 0.7977, 0.0059, 0.0237],\n",
      "        [0.5188, 0.3801, 0.0128, 0.0176],\n",
      "        [0.1405, 0.2013, 0.0052, 0.0213],\n",
      "        [0.6398, 0.1397, 0.0055, 0.0212],\n",
      "        [0.7660, 0.5292, 0.0145, 0.0346],\n",
      "        [0.2882, 0.3227, 0.0110, 0.0184],\n",
      "        [0.4436, 0.6728, 0.0079, 0.0228],\n",
      "        [0.1378, 0.0065, 0.0050, 0.0123],\n",
      "        [0.8792, 0.4703, 0.0057, 0.0203],\n",
      "        [0.2701, 0.3491, 0.0174, 0.0265],\n",
      "        [0.8640, 0.1587, 0.0054, 0.0190],\n",
      "        [0.2447, 0.7917, 0.0124, 0.0100],\n",
      "        [0.2672, 0.3537, 0.0159, 0.0249],\n",
      "        [0.6408, 0.2521, 0.0050, 0.0228]], device='cuda:0')\n",
      "xyxy: tensor([[1.3901e+03, 6.4305e+02, 1.4271e+03, 6.7885e+02],\n",
      "        [1.1181e+03, 1.4863e+03, 1.1453e+03, 1.5232e+03],\n",
      "        [1.1831e+03, 1.1737e+03, 1.2035e+03, 1.2131e+03],\n",
      "        [1.0654e+03, 2.8567e+02, 1.0966e+03, 3.1933e+02],\n",
      "        [1.0916e+03, 1.5383e+03, 1.1180e+03, 1.5737e+03],\n",
      "        [1.8290e+03, 9.4086e+00, 1.8458e+03, 4.7690e+01],\n",
      "        [1.2979e+03, 7.4121e+02, 1.3339e+03, 7.8558e+02],\n",
      "        [1.2645e+03, 8.1981e+02, 1.2919e+03, 8.5790e+02],\n",
      "        [1.2433e+03, 8.9297e+02, 1.2661e+03, 9.3068e+02],\n",
      "        [2.3424e+03, 3.8511e+02, 2.3594e+03, 4.0830e+02],\n",
      "        [3.8990e+02, 7.9310e+01, 4.0619e+02, 1.1230e+02],\n",
      "        [1.1665e+03, 1.6075e+02, 1.1999e+03, 1.9866e+02],\n",
      "        [2.3672e+03, 3.8346e+02, 2.3887e+03, 4.0772e+02],\n",
      "        [1.9669e+03, 6.7224e+02, 2.0528e+03, 7.3342e+02],\n",
      "        [1.2291e+03, 1.2732e+03, 1.2462e+03, 1.3115e+03],\n",
      "        [1.4758e+03, 6.0151e+02, 1.5125e+03, 6.3009e+02],\n",
      "        [3.9703e+02, 3.0885e+02, 4.1205e+02, 3.4340e+02],\n",
      "        [1.8346e+03, 2.0919e+02, 1.8504e+03, 2.4357e+02],\n",
      "        [2.1851e+03, 8.2932e+02, 2.2268e+03, 8.8544e+02],\n",
      "        [8.1411e+02, 5.0785e+02, 8.4581e+02, 5.3773e+02],\n",
      "        [1.2661e+03, 1.0715e+03, 1.2888e+03, 1.1085e+03],\n",
      "        [3.8962e+02, 6.5137e-01, 4.0409e+02, 2.0538e+01],\n",
      "        [2.5239e+03, 7.4543e+02, 2.5402e+03, 7.7838e+02],\n",
      "        [7.5287e+02, 5.4400e+02, 8.0301e+02, 5.8701e+02],\n",
      "        [2.4805e+03, 2.4170e+02, 2.4960e+03, 2.7244e+02],\n",
      "        [6.8673e+02, 1.2745e+03, 7.2250e+02, 1.2906e+03],\n",
      "        [7.4672e+02, 5.5277e+02, 7.9253e+02, 5.9310e+02],\n",
      "        [1.8383e+03, 3.8987e+02, 1.8526e+03, 4.2682e+02]], device='cuda:0')\n",
      "xyxyn: tensor([[4.8266e-01, 3.9694e-01, 4.9552e-01, 4.1904e-01],\n",
      "        [3.8823e-01, 9.1746e-01, 3.9766e-01, 9.4022e-01],\n",
      "        [4.1081e-01, 7.2450e-01, 4.1789e-01, 7.4884e-01],\n",
      "        [3.6995e-01, 1.7634e-01, 3.8078e-01, 1.9712e-01],\n",
      "        [3.7903e-01, 9.4957e-01, 3.8818e-01, 9.7142e-01],\n",
      "        [6.3507e-01, 5.8078e-03, 6.4092e-01, 2.9438e-02],\n",
      "        [4.5067e-01, 4.5754e-01, 4.6316e-01, 4.8493e-01],\n",
      "        [4.3906e-01, 5.0606e-01, 4.4857e-01, 5.2957e-01],\n",
      "        [4.3170e-01, 5.5122e-01, 4.3961e-01, 5.7449e-01],\n",
      "        [8.1333e-01, 2.3772e-01, 8.1923e-01, 2.5204e-01],\n",
      "        [1.3538e-01, 4.8957e-02, 1.4104e-01, 6.9322e-02],\n",
      "        [4.0505e-01, 9.9231e-02, 4.1663e-01, 1.2263e-01],\n",
      "        [8.2195e-01, 2.3671e-01, 8.2940e-01, 2.5168e-01],\n",
      "        [6.8296e-01, 4.1496e-01, 7.1279e-01, 4.5273e-01],\n",
      "        [4.2676e-01, 7.8590e-01, 4.3271e-01, 8.0960e-01],\n",
      "        [5.1244e-01, 3.7130e-01, 5.2519e-01, 3.8894e-01],\n",
      "        [1.3786e-01, 1.9065e-01, 1.4307e-01, 2.1198e-01],\n",
      "        [6.3702e-01, 1.2913e-01, 6.4250e-01, 1.5035e-01],\n",
      "        [7.5872e-01, 5.1192e-01, 7.7319e-01, 5.4656e-01],\n",
      "        [2.8268e-01, 3.1349e-01, 2.9368e-01, 3.3193e-01],\n",
      "        [4.3963e-01, 6.6143e-01, 4.4751e-01, 6.8427e-01],\n",
      "        [1.3528e-01, 4.0208e-04, 1.4031e-01, 1.2678e-02],\n",
      "        [8.7634e-01, 4.6014e-01, 8.8200e-01, 4.8048e-01],\n",
      "        [2.6141e-01, 3.3580e-01, 2.7882e-01, 3.6235e-01],\n",
      "        [8.6127e-01, 1.4920e-01, 8.6667e-01, 1.6817e-01],\n",
      "        [2.3845e-01, 7.8671e-01, 2.5087e-01, 7.9667e-01],\n",
      "        [2.5928e-01, 3.4121e-01, 2.7518e-01, 3.6611e-01],\n",
      "        [6.3830e-01, 2.4066e-01, 6.4327e-01, 2.6347e-01]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while cap.isOpened():\n",
    "    status, frame = cap.read()\n",
    "    if not status:\n",
    "        break\n",
    "\n",
    "    results = model(frame, stream=True)\n",
    "    print([x.boxes for x in results][0])\n",
    "    break\n",
    "    # for res in results:\n",
    "    #     filtered_indices = np.where(res.boxes.conf.cpu().numpy() > 0.3)[0]\n",
    "    #     boxes = res.boxes.xyxy.cpu().numpy()[filtered_indices].astype(int)\n",
    "    #     tracks = tracker.update(boxes)\n",
    "    #     tracks = tracks.astype(int)\n",
    "        \n",
    "    #     for xmin, ymin, xmax, ymax, track_id in tracks:\n",
    "    #         cv2.putText(img=frame, text=f\"Id: {track_id}\", org=(xmin, ymin-10), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=2, color=(0,255,0), thickness=2)\n",
    "    #         cv2.rectangle(img=frame, pt1=(xmin, ymin), pt2=(xmax, ymax), color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    resized_frame = resize_frame(frame)\n",
    "    cv2.imshow(\"frame\", resized_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5382a9",
   "metadata": {},
   "source": [
    "# Análisis del Algoritmo SORT\n",
    "\n",
    "El código proporcionado implementa el algoritmo SORT (Simple Online and Realtime Tracking), un método popular para el seguimiento de múltiples objetos en secuencias de video que, en combinación a un modelo de detección de objetos, entrega un arreglo de objetos con IDs únicos, algunos de sus componentes más importantes son:\n",
    "\n",
    "## 1. Modelo de Filtro Kalman\n",
    "El Filtro Kalman se emplea para predecir la posición futura de cada objeto en base a sus estados actuales y pasados. En el código, esto se maneja a través de la clase `KalmanBoxTracker`.\n",
    "\n",
    "## 2. Asociación de Detecciones con Rastreadores\n",
    "El algoritmo asocia las detecciones de objetos en cada frame del video con los rastreadores existentes. Esto se realiza mediante la función `associate_detections_to_trackers`, que utiliza el IoU (Intersección sobre la Unión) y un algoritmo de asignación lineal para encontrar la mejor correspondencia entre las detecciones actuales y los rastreadores existentes.\n",
    "\n",
    "## 3. Manejo de la Vida Útil de los Rastreadores\n",
    "Los rastreadores se actualizan o eliminan en función de su edad y el número de veces que han sido emparejados con detecciones. Esto permite que el algoritmo maneje situaciones donde los objetos pueden temporalmente desaparecer y reaparecer en el campo de visión.\n",
    "\n",
    " SORT rastrea objetos en videos al asociar detecciones de objetos en cada frame con rastreadores existentes utilizando el cálculo de IoU y actualiza estos rastreadores con información de movimiento utilizando filtros Kalman. Ahora, si bien su desarrollo es simple, es importante destacar que este cuenta con algunas limitaciones a estudiar, al presentar una baja fiabilidad cuando la detección presenta pérdidas importantes sobre el objeto que se busca seguir. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
